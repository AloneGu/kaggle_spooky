{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Embedding, LSTM, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "import gc\n",
    "\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "test_df = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "# replace\n",
    "# train_df['text'] = train_df['text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "# test_df['text'] =test_df['text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cnn done\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_feats():\n",
    "    # return train pred prob and test pred prob \n",
    "    NUM_WORDS = 30000\n",
    "    N = 10\n",
    "    MAX_LEN = 150\n",
    "    NUM_CLASSES = 3\n",
    "    MODEL_P = '/tmp/lstm.h5'\n",
    "    \n",
    "    X = train_df['text']\n",
    "    Y = train_df['author']\n",
    "    X_test = test_df['text']\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "\n",
    "    train_x = tokenizer.texts_to_sequences(X)\n",
    "    train_x = pad_sequences(train_x, maxlen=MAX_LEN)\n",
    "    \n",
    "    test_x = tokenizer.texts_to_sequences(X_test)\n",
    "    test_x = pad_sequences(test_x, maxlen=MAX_LEN)\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(Y)\n",
    "\n",
    "    train_y = lb.transform(Y)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
    "#     model.add(Conv1D(16,\n",
    "#                      3,\n",
    "#                      padding='valid',\n",
    "#                      activation='relu',\n",
    "#                      strides=1))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    model_chk = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    np.random.seed(42)\n",
    "    model.fit(train_x, train_y, \n",
    "              validation_split=0.1,\n",
    "              batch_size=64, epochs=20, \n",
    "              verbose=2,\n",
    "              callbacks=[model_chk],\n",
    "              shuffle=False\n",
    "             )\n",
    "    \n",
    "    model = load_model(MODEL_P)\n",
    "    train_pred = model.predict(train_x)\n",
    "    test_pred = model.predict(test_x)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    print(log_loss(train_y,train_pred))\n",
    "    return train_pred,test_pred\n",
    "\n",
    "print('def cnn done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 150, 10)           300000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 300,423\n",
      "Trainable params: 300,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/20\n",
      "Epoch 00001: val_loss improved from inf to 1.06971, saving model to /tmp/lstm.h5\n",
      " - 2s - loss: 1.0841 - acc: 0.4024 - val_loss: 1.0697 - val_acc: 0.4055\n",
      "Epoch 2/20\n",
      "Epoch 00002: val_loss improved from 1.06971 to 0.91425, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 1.0040 - acc: 0.4832 - val_loss: 0.9142 - val_acc: 0.5577\n",
      "Epoch 3/20\n",
      "Epoch 00003: val_loss improved from 0.91425 to 0.70341, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.7878 - acc: 0.6836 - val_loss: 0.7034 - val_acc: 0.7503\n",
      "Epoch 4/20\n",
      "Epoch 00004: val_loss improved from 0.70341 to 0.56475, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.5830 - acc: 0.7998 - val_loss: 0.5647 - val_acc: 0.7926\n",
      "Epoch 5/20\n",
      "Epoch 00005: val_loss improved from 0.56475 to 0.49066, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.4556 - acc: 0.8423 - val_loss: 0.4907 - val_acc: 0.8080\n",
      "Epoch 6/20\n",
      "Epoch 00006: val_loss improved from 0.49066 to 0.44483, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.3740 - acc: 0.8709 - val_loss: 0.4448 - val_acc: 0.8253\n",
      "Epoch 7/20\n",
      "Epoch 00007: val_loss improved from 0.44483 to 0.41809, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.3136 - acc: 0.8931 - val_loss: 0.4181 - val_acc: 0.8325\n",
      "Epoch 8/20\n",
      "Epoch 00008: val_loss improved from 0.41809 to 0.39809, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.2670 - acc: 0.9124 - val_loss: 0.3981 - val_acc: 0.8366\n",
      "Epoch 9/20\n",
      "Epoch 00009: val_loss improved from 0.39809 to 0.38763, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.2299 - acc: 0.9235 - val_loss: 0.3876 - val_acc: 0.8417\n",
      "Epoch 10/20\n",
      "Epoch 00010: val_loss improved from 0.38763 to 0.37877, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.1999 - acc: 0.9361 - val_loss: 0.3788 - val_acc: 0.8504\n",
      "Epoch 11/20\n",
      "Epoch 00011: val_loss improved from 0.37877 to 0.37649, saving model to /tmp/lstm.h5\n",
      " - 1s - loss: 0.1750 - acc: 0.9443 - val_loss: 0.3765 - val_acc: 0.8534\n",
      "Epoch 12/20\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.1548 - acc: 0.9518 - val_loss: 0.3772 - val_acc: 0.8565\n",
      "Epoch 13/20\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.1345 - acc: 0.9587 - val_loss: 0.3795 - val_acc: 0.8565\n",
      "Epoch 14/20\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.1200 - acc: 0.9635 - val_loss: 0.3849 - val_acc: 0.8565\n",
      "Epoch 15/20\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.1073 - acc: 0.9686 - val_loss: 0.3938 - val_acc: 0.8560\n",
      "Epoch 16/20\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 1s - loss: 0.0970 - acc: 0.9711 - val_loss: 0.4055 - val_acc: 0.8606\n",
      "Epoch 17/20\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 1s - loss: 0.0866 - acc: 0.9741 - val_loss: 0.4130 - val_acc: 0.8570\n",
      "Epoch 18/20\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 1s - loss: 0.0774 - acc: 0.9785 - val_loss: 0.4252 - val_acc: 0.8570\n",
      "Epoch 19/20\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 1s - loss: 0.0697 - acc: 0.9805 - val_loss: 0.4446 - val_acc: 0.8596\n",
      "Epoch 20/20\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 1s - loss: 0.0621 - acc: 0.9828 - val_loss: 0.4616 - val_acc: 0.8575\n",
      "0.168143216387\n"
     ]
    }
   ],
   "source": [
    "cnn_train,cnn_test = get_cnn_feats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
