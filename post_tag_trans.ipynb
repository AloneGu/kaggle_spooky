{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "\n",
    "test_sentence = \"\"\"Sentence boundary disambiguation (SBD), also known as sentence breaking, is the problem in natural language processing of deciding where sentences begin and end. Languages like Japanese and Chinese have unambiguous sentence-ending markers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentence boundary disambiguation (SBD), also known as sentence breaking, is the problem in natural language processing of deciding where sentences begin and end.', 'Languages like Japanese and Chinese have unambiguous sentence-ending markers.']\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(test_sentence)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Languages', 'NNS'), ('like', 'IN'), Tree('GPE', [('Japanese', 'JJ')]), ('and', 'CC'), Tree('GPE', [('Chinese', 'JJ')]), ('have', 'VBP'), ('unambiguous', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "tags = nltk.pos_tag(word_tokenize(\"Languages like Japanese and Chinese have unambiguous\"))\n",
    "print(list(nltk.ne_chunk(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP JJ NN ( NNP ) , RB VBN IN NN NN , VBZ DT NN IN JJ NN NN IN VBG WRB NNS VBP CC VBP .. NNS IN JJ CC JJ VBP JJ JJ NNS .\n",
      "B-GPE O O O B-ORGANIZATION O O O O O O O O O O O O O O O O O O O O O O O. O O B-GPE O B-GPE O O O O O\n"
     ]
    }
   ],
   "source": [
    "# >>> text = word_tokenize(\"And now for something completely different\")\n",
    "# >>> nltk.pos_tag(text)\n",
    "# [('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'),\n",
    "# ('completely', 'RB'), ('different', 'JJ')]\n",
    "\n",
    "def pos_tag_text(s):\n",
    "    sents = nltk.sent_tokenize(test_sentence)\n",
    "    res = []\n",
    "    for sent in sents:\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        tag_res = [a[1] for a in nltk.pos_tag(words)]\n",
    "        res.append(' '.join(tag_res))\n",
    "    return '. '.join(res)\n",
    "\n",
    "def ne_text(s):\n",
    "    sents = nltk.sent_tokenize(test_sentence)\n",
    "    res = []\n",
    "    for sent in sents:\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        tag_res = nltk.pos_tag(words)\n",
    "        ne_tree = nltk.ne_chunk(tag_res)\n",
    "        list_res = nltk.tree2conlltags(ne_tree)\n",
    "        ne_res = [a[2] for a in list_res]\n",
    "        res.append(' '.join(ne_res))\n",
    "    return '. '.join(res)\n",
    "\n",
    "print(pos_tag_text(test_sentence))\n",
    "print(ne_text(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
