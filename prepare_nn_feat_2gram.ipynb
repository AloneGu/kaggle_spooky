{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "test_df = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "# trans text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He shall find that I can feel my injuries; he shall learn to dread my revenge\" A few days after he arrived.\n",
      "he--shall shall--find find--that that--i i--can can--feel feel--my my--injuries injuries--; ;--he he--shall shall--learn learn--to to--dread dread--my my--revenge revenge--\" \"--a a--few few--days days--after after--he he--arrived.\n"
     ]
    }
   ],
   "source": [
    "def trans_text(s):\n",
    "    s = s.replace(\"' \", \" ' \")\n",
    "    p = ['. ', '; ', '\" ', '! ', '? ', ', ',': ']\n",
    "    for tmp_p in p:\n",
    "        s=s.replace(tmp_p,' {}'.format(tmp_p))\n",
    "    s = s.lower()\n",
    "    words = s.split(' ')\n",
    "    word_cnt = len(words)\n",
    "    new_words = []\n",
    "    for i in range(word_cnt-1):\n",
    "        new_words.append('{}--{}'.format(words[i],words[i+1]))\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "print(train_df['text'][10])\n",
    "train_df['text'] = train_df['text'].apply(trans_text)\n",
    "test_df['text'] = test_df['text'].apply(trans_text)\n",
    "print(train_df['text'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import keras done\n"
     ]
    }
   ],
   "source": [
    "# add cnn feat\n",
    "from keras.layers import Embedding, CuDNNLSTM, Dense, Flatten, Dropout, LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "print('import keras done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cnn done\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.80816, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 1.0086 - acc: 0.4860 - val_loss: 0.8082 - val_acc: 0.6784\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.80816 to 0.51656, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.6132 - acc: 0.7602 - val_loss: 0.5166 - val_acc: 0.7996\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.51656 to 0.44420, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3716 - acc: 0.8734 - val_loss: 0.4442 - val_acc: 0.8168\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.2524 - acc: 0.9166 - val_loss: 0.4457 - val_acc: 0.8226\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.1791 - acc: 0.9437 - val_loss: 0.4683 - val_acc: 0.8232\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.1333 - acc: 0.9595 - val_loss: 0.5136 - val_acc: 0.8232\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1022 - acc: 0.9718 - val_loss: 0.5784 - val_acc: 0.8143\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.0821 - acc: 0.9774 - val_loss: 0.6386 - val_acc: 0.8079\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.0675 - acc: 0.9821 - val_loss: 0.6871 - val_acc: 0.8117\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0560 - acc: 0.9847 - val_loss: 0.7581 - val_acc: 0.8022\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.84571, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 1.0178 - acc: 0.4772 - val_loss: 0.8457 - val_acc: 0.6209\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.84571 to 0.62877, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.6866 - acc: 0.7102 - val_loss: 0.6288 - val_acc: 0.7454\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.62877 to 0.52419, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.4512 - acc: 0.8300 - val_loss: 0.5242 - val_acc: 0.7900\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss improved from 0.52419 to 0.49779, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 0.3085 - acc: 0.8957 - val_loss: 0.4978 - val_acc: 0.8041\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 2s - loss: 0.2183 - acc: 0.9314 - val_loss: 0.5188 - val_acc: 0.8015\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.1609 - acc: 0.9545 - val_loss: 0.5562 - val_acc: 0.8105\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1248 - acc: 0.9641 - val_loss: 0.6088 - val_acc: 0.8066\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1022 - acc: 0.9728 - val_loss: 0.6728 - val_acc: 0.7932\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.0802 - acc: 0.9763 - val_loss: 0.7201 - val_acc: 0.7958\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.0618 - acc: 0.9810 - val_loss: 0.7938 - val_acc: 0.7983\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.72331, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 0.9823 - acc: 0.5096 - val_loss: 0.7233 - val_acc: 0.7281\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.72331 to 0.48132, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5147 - acc: 0.8082 - val_loss: 0.4813 - val_acc: 0.8105\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.48132 to 0.45450, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 0.3012 - acc: 0.8917 - val_loss: 0.4545 - val_acc: 0.8213\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 2s - loss: 0.1993 - acc: 0.9298 - val_loss: 0.4782 - val_acc: 0.8232\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.1426 - acc: 0.9522 - val_loss: 0.5217 - val_acc: 0.8302\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 2s - loss: 0.1049 - acc: 0.9664 - val_loss: 0.5809 - val_acc: 0.8200\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.0786 - acc: 0.9751 - val_loss: 0.6501 - val_acc: 0.8232\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.0620 - acc: 0.9823 - val_loss: 0.7210 - val_acc: 0.8200\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.0499 - acc: 0.9847 - val_loss: 0.7834 - val_acc: 0.8226\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0421 - acc: 0.9876 - val_loss: 0.8416 - val_acc: 0.8143\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.85677, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 1.0169 - acc: 0.4713 - val_loss: 0.8568 - val_acc: 0.5629\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.85677 to 0.54534, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.6414 - acc: 0.7367 - val_loss: 0.5453 - val_acc: 0.7754\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.54534 to 0.44695, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3871 - acc: 0.8563 - val_loss: 0.4470 - val_acc: 0.8277\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss improved from 0.44695 to 0.43415, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2641 - acc: 0.9066 - val_loss: 0.4341 - val_acc: 0.8379\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.1924 - acc: 0.9357 - val_loss: 0.4392 - val_acc: 0.8398\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.1456 - acc: 0.9518 - val_loss: 0.4650 - val_acc: 0.8392\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1173 - acc: 0.9634 - val_loss: 0.4976 - val_acc: 0.8373\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.0940 - acc: 0.9706 - val_loss: 0.5396 - val_acc: 0.8290\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.0782 - acc: 0.9753 - val_loss: 0.5918 - val_acc: 0.8277\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 2s - loss: 0.0684 - acc: 0.9802 - val_loss: 0.6396 - val_acc: 0.8251\n",
      "------------------\n",
      "Train on 14097 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.71145, saving model to /tmp/nn_model.h5\n",
      " - 2s - loss: 0.9704 - acc: 0.5193 - val_loss: 0.7115 - val_acc: 0.7128\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.71145 to 0.47008, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5325 - acc: 0.7957 - val_loss: 0.4701 - val_acc: 0.8130\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.47008 to 0.43588, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3155 - acc: 0.8867 - val_loss: 0.4359 - val_acc: 0.8290\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 1s - loss: 0.2125 - acc: 0.9276 - val_loss: 0.4591 - val_acc: 0.8283\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 1s - loss: 0.1497 - acc: 0.9508 - val_loss: 0.5086 - val_acc: 0.8271\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 1s - loss: 0.1119 - acc: 0.9651 - val_loss: 0.5677 - val_acc: 0.8117\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.0854 - acc: 0.9737 - val_loss: 0.6286 - val_acc: 0.8137\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.0663 - acc: 0.9806 - val_loss: 0.6760 - val_acc: 0.8137\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.0533 - acc: 0.9840 - val_loss: 0.7370 - val_acc: 0.8105\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0456 - acc: 0.9864 - val_loss: 0.8203 - val_acc: 0.8003\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_feats(rnd=1):\n",
    "    # return train pred prob and test pred prob \n",
    "    train_pred, test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    best_val_train_pred, best_val_test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    FEAT_CNT = 5\n",
    "    NUM_WORDS = 30000\n",
    "    N = 10\n",
    "    MAX_LEN = 100\n",
    "    NUM_CLASSES = 3\n",
    "    MODEL_P = '/tmp/nn_model.h5'\n",
    "    \n",
    "    tmp_X = train_df['text']\n",
    "    tmp_Y = train_df['author']\n",
    "    tmp_X_test = test_df['text']\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(tmp_X)\n",
    "\n",
    "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
    "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
    "    \n",
    "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
    "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(tmp_Y)\n",
    "\n",
    "    ttrain_y = lb.transform(tmp_Y)\n",
    "    \n",
    "    kf = KFold(n_splits=FEAT_CNT, shuffle=True, random_state=233*rnd)\n",
    "    for train_index, test_index in kf.split(tmp_X):\n",
    "        # prepare aug train, val\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
    "        model.add(Conv1D(16,\n",
    "                         3,\n",
    "                         padding='valid',\n",
    "                         activation='relu',\n",
    "                         strides=1))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        #model.summary()\n",
    "\n",
    "        model_chk = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        model.fit(ttrain_x[train_index], ttrain_y[train_index], \n",
    "                  validation_split=0.1,\n",
    "                  batch_size=32, epochs=10, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk],\n",
    "                  shuffle=False\n",
    "                 )\n",
    " \n",
    "        # save feat\n",
    "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        # best val model\n",
    "        model = load_model(MODEL_P)\n",
    "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        # release\n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('------------------')\n",
    "        \n",
    "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred\n",
    "\n",
    "print('def cnn done')\n",
    "\n",
    "cnn_train1,cnn_test1,cnn_train2,cnn_test2 = get_cnn_feats(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def lstm done\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.73654, saving model to /tmp/nn_model.h5\n",
      " - 40s - loss: 0.9829 - acc: 0.5041 - val_loss: 0.7365 - val_acc: 0.6911\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.73654 to 0.48577, saving model to /tmp/nn_model.h5\n",
      " - 39s - loss: 0.5336 - acc: 0.7875 - val_loss: 0.4858 - val_acc: 0.8015\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.48577 to 0.47234, saving model to /tmp/nn_model.h5\n",
      " - 39s - loss: 0.2979 - acc: 0.8903 - val_loss: 0.4723 - val_acc: 0.8105\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 39s - loss: 0.1934 - acc: 0.9321 - val_loss: 0.5211 - val_acc: 0.8060\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 39s - loss: 0.1380 - acc: 0.9513 - val_loss: 0.5457 - val_acc: 0.8168\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 40s - loss: 0.1115 - acc: 0.9609 - val_loss: 0.6049 - val_acc: 0.8105\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 40s - loss: 0.0895 - acc: 0.9694 - val_loss: 0.7658 - val_acc: 0.7977\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 40s - loss: 0.0701 - acc: 0.9767 - val_loss: 0.7462 - val_acc: 0.8162\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 39s - loss: 0.0587 - acc: 0.9796 - val_loss: 0.8445 - val_acc: 0.8073\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 38s - loss: 0.0533 - acc: 0.9824 - val_loss: 0.8200 - val_acc: 0.8066\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.77063, saving model to /tmp/nn_model.h5\n",
      " - 41s - loss: 0.9876 - acc: 0.5044 - val_loss: 0.7706 - val_acc: 0.6816\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.77063 to 0.50514, saving model to /tmp/nn_model.h5\n",
      " - 40s - loss: 0.5367 - acc: 0.7892 - val_loss: 0.5051 - val_acc: 0.7964\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 40s - loss: 0.2966 - acc: 0.8912 - val_loss: 0.5167 - val_acc: 0.8034\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 40s - loss: 0.1919 - acc: 0.9318 - val_loss: 0.5563 - val_acc: 0.8105\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 40s - loss: 0.1393 - acc: 0.9521 - val_loss: 0.6244 - val_acc: 0.8079\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 41s - loss: 0.1026 - acc: 0.9650 - val_loss: 0.7052 - val_acc: 0.8098\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 40s - loss: 0.0782 - acc: 0.9732 - val_loss: 0.7773 - val_acc: 0.8028\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 39s - loss: 0.0674 - acc: 0.9768 - val_loss: 0.8300 - val_acc: 0.7996\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 38s - loss: 0.0599 - acc: 0.9806 - val_loss: 0.8670 - val_acc: 0.8111\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 39s - loss: 0.0502 - acc: 0.9823 - val_loss: 0.9372 - val_acc: 0.7977\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.73787, saving model to /tmp/nn_model.h5\n",
      " - 43s - loss: 0.9844 - acc: 0.5043 - val_loss: 0.7379 - val_acc: 0.6969\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.73787 to 0.49495, saving model to /tmp/nn_model.h5\n",
      " - 42s - loss: 0.5250 - acc: 0.7936 - val_loss: 0.4950 - val_acc: 0.7971\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 43s - loss: 0.2922 - acc: 0.8929 - val_loss: 0.5068 - val_acc: 0.7964\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 44s - loss: 0.1922 - acc: 0.9315 - val_loss: 0.5464 - val_acc: 0.8073\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 44s - loss: 0.1301 - acc: 0.9533 - val_loss: 0.6232 - val_acc: 0.8137\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 45s - loss: 0.0964 - acc: 0.9656 - val_loss: 0.7116 - val_acc: 0.8111\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 46s - loss: 0.0831 - acc: 0.9713 - val_loss: 0.7495 - val_acc: 0.8054\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 46s - loss: 0.0652 - acc: 0.9778 - val_loss: 0.8211 - val_acc: 0.8028\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 45s - loss: 0.0512 - acc: 0.9818 - val_loss: 0.8961 - val_acc: 0.8079\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 44s - loss: 0.0478 - acc: 0.9838 - val_loss: 0.9807 - val_acc: 0.7913\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.72360, saving model to /tmp/nn_model.h5\n",
      " - 48s - loss: 0.9907 - acc: 0.4960 - val_loss: 0.7236 - val_acc: 0.7090\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.72360 to 0.47069, saving model to /tmp/nn_model.h5\n",
      " - 45s - loss: 0.5244 - acc: 0.7890 - val_loss: 0.4707 - val_acc: 0.8086\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.47069 to 0.46512, saving model to /tmp/nn_model.h5\n",
      " - 45s - loss: 0.2977 - acc: 0.8893 - val_loss: 0.4651 - val_acc: 0.8175\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 41s - loss: 0.1972 - acc: 0.9324 - val_loss: 0.4950 - val_acc: 0.8213\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 41s - loss: 0.1452 - acc: 0.9501 - val_loss: 0.5694 - val_acc: 0.8156\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 41s - loss: 0.1066 - acc: 0.9634 - val_loss: 0.6234 - val_acc: 0.8156\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 42s - loss: 0.0868 - acc: 0.9704 - val_loss: 0.6505 - val_acc: 0.8124\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 42s - loss: 0.0716 - acc: 0.9754 - val_loss: 0.7032 - val_acc: 0.8168\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 43s - loss: 0.0601 - acc: 0.9788 - val_loss: 0.8018 - val_acc: 0.8060\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 46s - loss: 0.0498 - acc: 0.9823 - val_loss: 0.8067 - val_acc: 0.8054\n",
      "------------------\n",
      "Train on 14097 samples, validate on 1567 samples\n",
      "Epoch 1/10\n",
      "Epoch 00001: val_loss improved from inf to 0.80109, saving model to /tmp/nn_model.h5\n",
      " - 88s - loss: 0.9962 - acc: 0.4946 - val_loss: 0.8011 - val_acc: 0.6599\n",
      "Epoch 2/10\n",
      "Epoch 00002: val_loss improved from 0.80109 to 0.49500, saving model to /tmp/nn_model.h5\n",
      " - 87s - loss: 0.6006 - acc: 0.7539 - val_loss: 0.4950 - val_acc: 0.7958\n",
      "Epoch 3/10\n",
      "Epoch 00003: val_loss improved from 0.49500 to 0.46804, saving model to /tmp/nn_model.h5\n",
      " - 90s - loss: 0.3251 - acc: 0.8803 - val_loss: 0.4680 - val_acc: 0.8156\n",
      "Epoch 4/10\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 93s - loss: 0.2066 - acc: 0.9270 - val_loss: 0.5344 - val_acc: 0.8181\n",
      "Epoch 5/10\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 91s - loss: 0.1417 - acc: 0.9508 - val_loss: 0.5946 - val_acc: 0.8111\n",
      "Epoch 6/10\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 61s - loss: 0.1090 - acc: 0.9634 - val_loss: 0.6355 - val_acc: 0.8137\n",
      "Epoch 7/10\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 46s - loss: 0.0832 - acc: 0.9723 - val_loss: 0.6990 - val_acc: 0.8130\n",
      "Epoch 8/10\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 51s - loss: 0.0710 - acc: 0.9750 - val_loss: 0.7816 - val_acc: 0.8003\n",
      "Epoch 9/10\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 46s - loss: 0.0589 - acc: 0.9798 - val_loss: 0.8132 - val_acc: 0.8034\n",
      "Epoch 10/10\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 52s - loss: 0.0504 - acc: 0.9830 - val_loss: 0.9959 - val_acc: 0.7875\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# add lstm feat\n",
    "def get_lstm_feats(rnd=1):\n",
    "    # return train pred prob and test pred prob \n",
    "    train_pred, test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    best_val_train_pred, best_val_test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    FEAT_CNT = 5\n",
    "    NUM_WORDS = 16000\n",
    "    N = 12\n",
    "    MAX_LEN = 300\n",
    "    NUM_CLASSES = 3\n",
    "    MODEL_P = '/tmp/nn_model.h5'\n",
    "    \n",
    "    tmp_X = train_df['text']\n",
    "    tmp_Y = train_df['author']\n",
    "    tmp_X_test = test_df['text']\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(tmp_X)\n",
    "\n",
    "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
    "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
    "    \n",
    "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
    "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(tmp_Y)\n",
    "\n",
    "    ttrain_y = lb.transform(tmp_Y)\n",
    "    \n",
    "    kf = KFold(n_splits=FEAT_CNT, shuffle=True, random_state=233*rnd)\n",
    "    for train_index, test_index in kf.split(tmp_X):\n",
    "        # prepare aug train, val\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
    "        model.add(LSTM(N, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        #model.summary()\n",
    "\n",
    "        model_chk = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        model.fit(ttrain_x[train_index], ttrain_y[train_index], \n",
    "                  validation_split=0.1,\n",
    "                  batch_size=128, epochs=10, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk],\n",
    "                  shuffle=False\n",
    "                 )\n",
    " \n",
    "        # save feat\n",
    "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        # best val model\n",
    "        model = load_model(MODEL_P)\n",
    "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('------------------')\n",
    "        \n",
    "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred\n",
    "\n",
    "print('def lstm done')\n",
    "lstm_train1,lstm_test1,lstm_train2,lstm_test2 = get_lstm_feats(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cnn done\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/15\n",
      "Epoch 00001: val_loss improved from inf to 0.99401, saving model to /tmp/nn_model.h5\n",
      " - 3s - loss: 1.0648 - acc: 0.4279 - val_loss: 0.9940 - val_acc: 0.5488\n",
      "Epoch 2/15\n",
      "Epoch 00002: val_loss improved from 0.99401 to 0.72789, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.8420 - acc: 0.6427 - val_loss: 0.7279 - val_acc: 0.7052\n",
      "Epoch 3/15\n",
      "Epoch 00003: val_loss improved from 0.72789 to 0.55303, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5654 - acc: 0.8021 - val_loss: 0.5530 - val_acc: 0.7843\n",
      "Epoch 4/15\n",
      "Epoch 00004: val_loss improved from 0.55303 to 0.47290, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3903 - acc: 0.8707 - val_loss: 0.4729 - val_acc: 0.8149\n",
      "Epoch 5/15\n",
      "Epoch 00005: val_loss improved from 0.47290 to 0.43808, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2901 - acc: 0.9054 - val_loss: 0.4381 - val_acc: 0.8302\n",
      "Epoch 6/15\n",
      "Epoch 00006: val_loss improved from 0.43808 to 0.42626, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2245 - acc: 0.9304 - val_loss: 0.4263 - val_acc: 0.8302\n",
      "Epoch 7/15\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1785 - acc: 0.9445 - val_loss: 0.4263 - val_acc: 0.8328\n",
      "Epoch 8/15\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1448 - acc: 0.9581 - val_loss: 0.4379 - val_acc: 0.8328\n",
      "Epoch 9/15\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.1204 - acc: 0.9657 - val_loss: 0.4514 - val_acc: 0.8322\n",
      "Epoch 10/15\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0984 - acc: 0.9741 - val_loss: 0.4664 - val_acc: 0.8334\n",
      "Epoch 11/15\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.0819 - acc: 0.9784 - val_loss: 0.4819 - val_acc: 0.8379\n",
      "Epoch 12/15\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.0701 - acc: 0.9811 - val_loss: 0.5079 - val_acc: 0.8271\n",
      "Epoch 13/15\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0601 - acc: 0.9845 - val_loss: 0.5266 - val_acc: 0.8309\n",
      "Epoch 14/15\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.0513 - acc: 0.9875 - val_loss: 0.5510 - val_acc: 0.8245\n",
      "Epoch 15/15\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.0443 - acc: 0.9894 - val_loss: 0.5732 - val_acc: 0.8271\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/15\n",
      "Epoch 00001: val_loss improved from inf to 1.00517, saving model to /tmp/nn_model.h5\n",
      " - 3s - loss: 1.0660 - acc: 0.4328 - val_loss: 1.0052 - val_acc: 0.5061\n",
      "Epoch 2/15\n",
      "Epoch 00002: val_loss improved from 1.00517 to 0.75357, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.8541 - acc: 0.6173 - val_loss: 0.7536 - val_acc: 0.6873\n",
      "Epoch 3/15\n",
      "Epoch 00003: val_loss improved from 0.75357 to 0.56606, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5847 - acc: 0.7943 - val_loss: 0.5661 - val_acc: 0.7958\n",
      "Epoch 4/15\n",
      "Epoch 00004: val_loss improved from 0.56606 to 0.47355, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.4030 - acc: 0.8675 - val_loss: 0.4736 - val_acc: 0.8239\n",
      "Epoch 5/15\n",
      "Epoch 00005: val_loss improved from 0.47355 to 0.43140, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2958 - acc: 0.9046 - val_loss: 0.4314 - val_acc: 0.8283\n",
      "Epoch 6/15\n",
      "Epoch 00006: val_loss improved from 0.43140 to 0.41541, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2279 - acc: 0.9265 - val_loss: 0.4154 - val_acc: 0.8302\n",
      "Epoch 7/15\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1763 - acc: 0.9457 - val_loss: 0.4174 - val_acc: 0.8258\n",
      "Epoch 8/15\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1414 - acc: 0.9582 - val_loss: 0.4216 - val_acc: 0.8239\n",
      "Epoch 9/15\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.1162 - acc: 0.9669 - val_loss: 0.4353 - val_acc: 0.8168\n",
      "Epoch 10/15\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0965 - acc: 0.9739 - val_loss: 0.4504 - val_acc: 0.8232\n",
      "Epoch 11/15\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.0816 - acc: 0.9782 - val_loss: 0.4688 - val_acc: 0.8143\n",
      "Epoch 12/15\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.0680 - acc: 0.9823 - val_loss: 0.4890 - val_acc: 0.8130\n",
      "Epoch 13/15\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0583 - acc: 0.9848 - val_loss: 0.5145 - val_acc: 0.8111\n",
      "Epoch 14/15\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.0494 - acc: 0.9873 - val_loss: 0.5352 - val_acc: 0.8111\n",
      "Epoch 15/15\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.0427 - acc: 0.9896 - val_loss: 0.5657 - val_acc: 0.8060\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/15\n",
      "Epoch 00001: val_loss improved from inf to 0.99022, saving model to /tmp/nn_model.h5\n",
      " - 3s - loss: 1.0618 - acc: 0.4271 - val_loss: 0.9902 - val_acc: 0.5412\n",
      "Epoch 2/15\n",
      "Epoch 00002: val_loss improved from 0.99022 to 0.67017, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.8123 - acc: 0.6825 - val_loss: 0.6702 - val_acc: 0.7454\n",
      "Epoch 3/15\n",
      "Epoch 00003: val_loss improved from 0.67017 to 0.52385, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5199 - acc: 0.8153 - val_loss: 0.5238 - val_acc: 0.7920\n",
      "Epoch 4/15\n",
      "Epoch 00004: val_loss improved from 0.52385 to 0.45759, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3699 - acc: 0.8724 - val_loss: 0.4576 - val_acc: 0.8175\n",
      "Epoch 5/15\n",
      "Epoch 00005: val_loss improved from 0.45759 to 0.42576, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2787 - acc: 0.9093 - val_loss: 0.4258 - val_acc: 0.8290\n",
      "Epoch 6/15\n",
      "Epoch 00006: val_loss improved from 0.42576 to 0.41411, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2180 - acc: 0.9312 - val_loss: 0.4141 - val_acc: 0.8366\n",
      "Epoch 7/15\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1742 - acc: 0.9442 - val_loss: 0.4144 - val_acc: 0.8385\n",
      "Epoch 8/15\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1427 - acc: 0.9559 - val_loss: 0.4204 - val_acc: 0.8366\n",
      "Epoch 9/15\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.1169 - acc: 0.9652 - val_loss: 0.4346 - val_acc: 0.8334\n",
      "Epoch 10/15\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0976 - acc: 0.9725 - val_loss: 0.4488 - val_acc: 0.8290\n",
      "Epoch 11/15\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.0832 - acc: 0.9765 - val_loss: 0.4659 - val_acc: 0.8251\n",
      "Epoch 12/15\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.0703 - acc: 0.9811 - val_loss: 0.4908 - val_acc: 0.8213\n",
      "Epoch 13/15\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0606 - acc: 0.9847 - val_loss: 0.5117 - val_acc: 0.8200\n",
      "Epoch 14/15\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.0517 - acc: 0.9857 - val_loss: 0.5378 - val_acc: 0.8181\n",
      "Epoch 15/15\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.0455 - acc: 0.9875 - val_loss: 0.5620 - val_acc: 0.8130\n",
      "------------------\n",
      "Train on 14096 samples, validate on 1567 samples\n",
      "Epoch 1/15\n",
      "Epoch 00001: val_loss improved from inf to 0.99441, saving model to /tmp/nn_model.h5\n",
      " - 3s - loss: 1.0620 - acc: 0.4338 - val_loss: 0.9944 - val_acc: 0.5080\n",
      "Epoch 2/15\n",
      "Epoch 00002: val_loss improved from 0.99441 to 0.72066, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.8282 - acc: 0.6524 - val_loss: 0.7207 - val_acc: 0.7167\n",
      "Epoch 3/15\n",
      "Epoch 00003: val_loss improved from 0.72066 to 0.54945, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5483 - acc: 0.8087 - val_loss: 0.5494 - val_acc: 0.7951\n",
      "Epoch 4/15\n",
      "Epoch 00004: val_loss improved from 0.54945 to 0.46973, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3797 - acc: 0.8739 - val_loss: 0.4697 - val_acc: 0.8207\n",
      "Epoch 5/15\n",
      "Epoch 00005: val_loss improved from 0.46973 to 0.43711, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2809 - acc: 0.9078 - val_loss: 0.4371 - val_acc: 0.8322\n",
      "Epoch 6/15\n",
      "Epoch 00006: val_loss improved from 0.43711 to 0.42643, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2169 - acc: 0.9308 - val_loss: 0.4264 - val_acc: 0.8334\n",
      "Epoch 7/15\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1695 - acc: 0.9488 - val_loss: 0.4269 - val_acc: 0.8322\n",
      "Epoch 8/15\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1370 - acc: 0.9605 - val_loss: 0.4387 - val_acc: 0.8296\n",
      "Epoch 9/15\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.1132 - acc: 0.9671 - val_loss: 0.4560 - val_acc: 0.8264\n",
      "Epoch 10/15\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0925 - acc: 0.9744 - val_loss: 0.4825 - val_acc: 0.8239\n",
      "Epoch 11/15\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.0793 - acc: 0.9788 - val_loss: 0.5004 - val_acc: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.0656 - acc: 0.9833 - val_loss: 0.5375 - val_acc: 0.8092\n",
      "Epoch 13/15\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0557 - acc: 0.9860 - val_loss: 0.5603 - val_acc: 0.8086\n",
      "Epoch 14/15\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.0487 - acc: 0.9874 - val_loss: 0.5859 - val_acc: 0.8079\n",
      "Epoch 15/15\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.0406 - acc: 0.9903 - val_loss: 0.6099 - val_acc: 0.8054\n",
      "------------------\n",
      "Train on 14097 samples, validate on 1567 samples\n",
      "Epoch 1/15\n",
      "Epoch 00001: val_loss improved from inf to 1.00504, saving model to /tmp/nn_model.h5\n",
      " - 3s - loss: 1.0676 - acc: 0.4219 - val_loss: 1.0050 - val_acc: 0.5482\n",
      "Epoch 2/15\n",
      "Epoch 00002: val_loss improved from 1.00504 to 0.68632, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.8187 - acc: 0.6811 - val_loss: 0.6863 - val_acc: 0.7422\n",
      "Epoch 3/15\n",
      "Epoch 00003: val_loss improved from 0.68632 to 0.53039, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.5184 - acc: 0.8168 - val_loss: 0.5304 - val_acc: 0.7945\n",
      "Epoch 4/15\n",
      "Epoch 00004: val_loss improved from 0.53039 to 0.45894, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.3643 - acc: 0.8761 - val_loss: 0.4589 - val_acc: 0.8226\n",
      "Epoch 5/15\n",
      "Epoch 00005: val_loss improved from 0.45894 to 0.42539, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2696 - acc: 0.9113 - val_loss: 0.4254 - val_acc: 0.8315\n",
      "Epoch 6/15\n",
      "Epoch 00006: val_loss improved from 0.42539 to 0.41563, saving model to /tmp/nn_model.h5\n",
      " - 1s - loss: 0.2097 - acc: 0.9318 - val_loss: 0.4156 - val_acc: 0.8392\n",
      "Epoch 7/15\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 1s - loss: 0.1650 - acc: 0.9503 - val_loss: 0.4159 - val_acc: 0.8366\n",
      "Epoch 8/15\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 1s - loss: 0.1343 - acc: 0.9592 - val_loss: 0.4252 - val_acc: 0.8302\n",
      "Epoch 9/15\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 1s - loss: 0.1083 - acc: 0.9680 - val_loss: 0.4331 - val_acc: 0.8264\n",
      "Epoch 10/15\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 1s - loss: 0.0899 - acc: 0.9750 - val_loss: 0.4491 - val_acc: 0.8226\n",
      "Epoch 11/15\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 1s - loss: 0.0758 - acc: 0.9800 - val_loss: 0.4631 - val_acc: 0.8220\n",
      "Epoch 12/15\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 1s - loss: 0.0635 - acc: 0.9834 - val_loss: 0.4878 - val_acc: 0.8264\n",
      "Epoch 13/15\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 1s - loss: 0.0545 - acc: 0.9862 - val_loss: 0.5048 - val_acc: 0.8220\n",
      "Epoch 14/15\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 1s - loss: 0.0470 - acc: 0.9887 - val_loss: 0.5348 - val_acc: 0.8200\n",
      "Epoch 15/15\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 1s - loss: 0.0409 - acc: 0.9896 - val_loss: 0.5551 - val_acc: 0.8207\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "def get_nn_feats(rnd=1):\n",
    "    # return train pred prob and test pred prob \n",
    "    train_pred, test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    best_val_train_pred, best_val_test_pred = np.zeros((19579,3)),np.zeros((8392,3))\n",
    "    FEAT_CNT = 5\n",
    "    NUM_WORDS = 30000\n",
    "    N = 10\n",
    "    MAX_LEN = 100\n",
    "    NUM_CLASSES = 3\n",
    "    MODEL_P = '/tmp/nn_model.h5'\n",
    "    \n",
    "    tmp_X = train_df['text']\n",
    "    tmp_Y = train_df['author']\n",
    "    tmp_X_test = test_df['text']\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    tmp_Y = lb.fit_transform(tmp_Y)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(tmp_X)\n",
    "    \n",
    "    ttrain_x = tokenizer.texts_to_sequences(tmp_X)\n",
    "    ttrain_x = pad_sequences(ttrain_x, maxlen=MAX_LEN)\n",
    "    \n",
    "    ttest_x = tokenizer.texts_to_sequences(tmp_X_test)\n",
    "    ttest_x = pad_sequences(ttest_x, maxlen=MAX_LEN)\n",
    "\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(tmp_Y)\n",
    "\n",
    "    ttrain_y = lb.transform(tmp_Y)\n",
    "    \n",
    "    kf = KFold(n_splits=FEAT_CNT, shuffle=True, random_state=2331*rnd)\n",
    "    for train_index, test_index in kf.split(tmp_X):\n",
    "        # prepare aug train, val      \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        #model.summary()\n",
    "\n",
    "        model_chk = ModelCheckpoint(filepath=MODEL_P, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        model.fit(ttrain_x[train_index], ttrain_y[train_index], \n",
    "                  validation_split=0.1,\n",
    "                  batch_size=64, epochs=15, \n",
    "                  verbose=2,\n",
    "                  callbacks=[model_chk],\n",
    "                  shuffle=False\n",
    "                 )\n",
    " \n",
    "        # save feat\n",
    "        train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        # best val model\n",
    "        model = load_model(MODEL_P)\n",
    "        best_val_train_pred[test_index] = model.predict(ttrain_x[test_index])\n",
    "        best_val_test_pred += model.predict(ttest_x)/FEAT_CNT\n",
    "        \n",
    "        # release\n",
    "        del model\n",
    "        gc.collect()\n",
    "        print('------------------')\n",
    "        \n",
    "    return train_pred,test_pred,best_val_train_pred,best_val_test_pred\n",
    "\n",
    "print('def cnn done')\n",
    "\n",
    "nn_train1,nn_test1,nn_train2,nn_test2 = get_nn_feats(4)\n",
    "\n",
    "\n",
    "\n",
    "all_nn_train = np.hstack([lstm_train1, lstm_train2, \n",
    "                          cnn_train1, cnn_train2,\n",
    "                          nn_train1,nn_train2\n",
    "                         ])\n",
    "all_nn_test = np.hstack([lstm_test1, lstm_test2, \n",
    "                         cnn_test1, cnn_test2,\n",
    "                         nn_test1,nn_test2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('nn_2gram_feat.pkl','wb') as fout:\n",
    "    pickle.dump([all_nn_train,all_nn_test],fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
