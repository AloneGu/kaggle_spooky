{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 781)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train_y = train_df['author'].map(author_mapping_dict)\n",
    "train_Y = train_y\n",
    "\n",
    "\n",
    "with open('feat.pkl','rb') as fin:\n",
    "    f_train_X,f_test_X = pickle.load(fin)\n",
    "print(f_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "def cv_test(k_cnt=3, s_flag = False):\n",
    "    rnd = 42\n",
    "    if s_flag:\n",
    "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    else:\n",
    "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    test_pred = None\n",
    "    weighted_test_pred = None\n",
    "    org_train_pred = None\n",
    "    avg_k_score = 0\n",
    "    reverse_score = 0\n",
    "    best_loss = 100\n",
    "    best_single_pred = None\n",
    "    for train_index, test_index in kf.split(f_train_X,train_Y):\n",
    "        X_train, X_test = f_train_X[train_index], f_train_X[test_index]\n",
    "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "        \n",
    "        dtx = lgb.Dataset(X_train, label=y_train)\n",
    "        dtv = lgb.Dataset(X_test, label=y_test)\n",
    "        \n",
    "        params = {'learning_rate':0.05\n",
    "         ,'max_depth':4\n",
    "         ,'objective':'multiclass'\n",
    "         ,'num_class':3\n",
    "         ,'metric':{'multi_logloss'}\n",
    "         ,'num_leaves':128\n",
    "         ,'min_data_in_leaf':128\n",
    "         ,'bagging_fraction':0.85 \n",
    "         ,'feature_fraction':0.85 \n",
    "         ,'lambda_l1':1.0}\n",
    "        \n",
    "        m = lgb.train(params, train_set=dtx, valid_sets=dtv, valid_names=['val'],\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)\n",
    "        \n",
    "        # get res\n",
    "        train_pred = m.predict(X_train)\n",
    "        print(train_pred.shape,y_train.shape)\n",
    "        valid_pred = m.predict(X_test)\n",
    "        tmp_train_pred = m.predict(f_train_X)\n",
    "        \n",
    "        # cal score\n",
    "        train_score = log_loss(y_train,train_pred)\n",
    "        valid_score = log_loss(y_test,valid_pred)\n",
    "        print('train log loss',train_score,'valid log loss',valid_score)\n",
    "        avg_k_score += valid_score\n",
    "        rev_valid_score = 1.0/valid_score # use for weighted\n",
    "        reverse_score += rev_valid_score # sum\n",
    "        print('rev',rev_valid_score)\n",
    "        \n",
    "        if test_pred is None:\n",
    "            test_pred = m.predict(f_test_X)\n",
    "            weighted_test_pred = test_pred*rev_valid_score\n",
    "            org_train_pred = tmp_train_pred\n",
    "            best_loss = valid_score\n",
    "            best_single_pred = test_pred\n",
    "        else:\n",
    "            curr_pred = m.predict(f_test_X)\n",
    "            test_pred += curr_pred\n",
    "            weighted_test_pred += curr_pred*rev_valid_score # fix bug here\n",
    "            org_train_pred += tmp_train_pred\n",
    "            # find better single model\n",
    "            if valid_score < best_loss:\n",
    "                print('BETTER')\n",
    "                best_loss = valid_score\n",
    "                best_single_pred = curr_pred\n",
    "\n",
    "    # avg\n",
    "    test_pred = test_pred / k_cnt\n",
    "    print(test_pred.shape)\n",
    "    print(test_pred[:5])\n",
    "    org_train_pred = org_train_pred / k_cnt\n",
    "    avg_k_score = avg_k_score/k_cnt\n",
    "\n",
    "\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    submiss['EAP']=test_pred[:,0]\n",
    "    submiss['HPL']=test_pred[:,1]\n",
    "    submiss['MWS']=test_pred[:,2]\n",
    "    submiss.to_csv(\"results/lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('--------------')\n",
    "    print(reverse_score)\n",
    "    # weigthed\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = weighted_test_pred / reverse_score\n",
    "    weighted_test_pred = np.round(weighted_test_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/weighted_lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    # best single\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = np.round(best_single_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/single_lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    \n",
    "    # train log loss\n",
    "    print('local average valid loss',avg_k_score)\n",
    "    print('train log loss', log_loss(train_Y,org_train_pred))\n",
    "    \n",
    "print('def done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.330587\n",
      "[100]\tval's multi_logloss: 0.276405\n",
      "[150]\tval's multi_logloss: 0.264631\n",
      "[200]\tval's multi_logloss: 0.25943\n",
      "[250]\tval's multi_logloss: 0.257693\n",
      "[300]\tval's multi_logloss: 0.256492\n",
      "[350]\tval's multi_logloss: 0.255642\n",
      "[400]\tval's multi_logloss: 0.255138\n",
      "[450]\tval's multi_logloss: 0.254946\n",
      "[500]\tval's multi_logloss: 0.255105\n",
      "[550]\tval's multi_logloss: 0.255204\n",
      "Early stopping, best iteration is:\n",
      "[450]\tval's multi_logloss: 0.254946\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.130383614505 valid log loss 0.254890412683\n",
      "rev 3.92325466256\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.332671\n",
      "[100]\tval's multi_logloss: 0.282413\n",
      "[150]\tval's multi_logloss: 0.272987\n",
      "[200]\tval's multi_logloss: 0.269362\n",
      "[250]\tval's multi_logloss: 0.268323\n",
      "[300]\tval's multi_logloss: 0.267334\n",
      "[350]\tval's multi_logloss: 0.266816\n",
      "[400]\tval's multi_logloss: 0.267217\n",
      "[450]\tval's multi_logloss: 0.268296\n",
      "Early stopping, best iteration is:\n",
      "[362]\tval's multi_logloss: 0.266752\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.14393322089 valid log loss 0.267028429028\n",
      "rev 3.7449196089\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.325271\n",
      "[100]\tval's multi_logloss: 0.273891\n",
      "[150]\tval's multi_logloss: 0.263564\n",
      "[200]\tval's multi_logloss: 0.259371\n",
      "[250]\tval's multi_logloss: 0.257482\n",
      "[300]\tval's multi_logloss: 0.256674\n",
      "[350]\tval's multi_logloss: 0.256602\n",
      "[400]\tval's multi_logloss: 0.257113\n",
      "Early stopping, best iteration is:\n",
      "[322]\tval's multi_logloss: 0.25636\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.156457586755 valid log loss 0.256296173924\n",
      "rev 3.90173596699\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.332082\n",
      "[100]\tval's multi_logloss: 0.280995\n",
      "[150]\tval's multi_logloss: 0.269368\n",
      "[200]\tval's multi_logloss: 0.265261\n",
      "[250]\tval's multi_logloss: 0.264266\n",
      "[300]\tval's multi_logloss: 0.264241\n",
      "[350]\tval's multi_logloss: 0.264103\n",
      "[400]\tval's multi_logloss: 0.26408\n",
      "Early stopping, best iteration is:\n",
      "[325]\tval's multi_logloss: 0.263868\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.152607542433 valid log loss 0.264168943619\n",
      "rev 3.78545633071\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.32176\n",
      "[100]\tval's multi_logloss: 0.267622\n",
      "[150]\tval's multi_logloss: 0.2552\n",
      "[200]\tval's multi_logloss: 0.250212\n",
      "[250]\tval's multi_logloss: 0.248116\n",
      "[300]\tval's multi_logloss: 0.24692\n",
      "[350]\tval's multi_logloss: 0.246786\n",
      "[400]\tval's multi_logloss: 0.246172\n",
      "[450]\tval's multi_logloss: 0.246337\n",
      "[500]\tval's multi_logloss: 0.24683\n",
      "Early stopping, best iteration is:\n",
      "[408]\tval's multi_logloss: 0.246025\n",
      "(15664, 3) (15664,)\n",
      "train log loss 0.13953421346 valid log loss 0.245696333491\n",
      "rev 4.07006480639\n",
      "BETTER\n",
      "(8392, 3)\n",
      "[[  2.30633630e-02   4.28341784e-03   9.72653219e-01]\n",
      " [  9.98725367e-01   7.08417825e-04   5.66215166e-04]\n",
      " [  1.75483480e-03   9.97604059e-01   6.41105854e-04]\n",
      " [  8.56369550e-01   1.40332554e-01   3.29789594e-03]\n",
      " [  8.26741679e-01   1.13713328e-01   5.95449924e-02]]\n",
      "        id       EAP       HPL       MWS\n",
      "0  id02310  0.023063  0.004283  0.972653\n",
      "1  id24541  0.998725  0.000708  0.000566\n",
      "2  id00134  0.001755  0.997604  0.000641\n",
      "3  id27757  0.856370  0.140333  0.003298\n",
      "4  id04081  0.826742  0.113713  0.059545\n",
      "--------------\n",
      "19.4254313755\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0229  0.0042  0.9728\n",
      "1  id24541  0.9987  0.0007  0.0006\n",
      "2  id00134  0.0018  0.9976  0.0006\n",
      "3  id27757  0.8553  0.1413  0.0033\n",
      "4  id04081  0.8269  0.1136  0.0595\n",
      "---------------\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0202  0.0028  0.9770\n",
      "1  id24541  0.9983  0.0013  0.0004\n",
      "2  id00134  0.0024  0.9970  0.0007\n",
      "3  id27757  0.7474  0.2481  0.0045\n",
      "4  id04081  0.8344  0.1082  0.0575\n",
      "---------------\n",
      "local average valid loss 0.257616058549\n",
      "train log loss 0.158026987099\n"
     ]
    }
   ],
   "source": [
    "cv_test(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.335845\n",
      "[100]\tval's multi_logloss: 0.285236\n",
      "[150]\tval's multi_logloss: 0.275847\n",
      "[200]\tval's multi_logloss: 0.27231\n",
      "[250]\tval's multi_logloss: 0.270957\n",
      "[300]\tval's multi_logloss: 0.270868\n",
      "[350]\tval's multi_logloss: 0.271914\n",
      "Early stopping, best iteration is:\n",
      "[277]\tval's multi_logloss: 0.270739\n",
      "(13052, 3) (13052,)\n",
      "train log loss 0.151749886059 valid log loss 0.270773313197\n",
      "rev 3.69312613638\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.327873\n",
      "[100]\tval's multi_logloss: 0.274952\n",
      "[150]\tval's multi_logloss: 0.262453\n",
      "[200]\tval's multi_logloss: 0.256936\n",
      "[250]\tval's multi_logloss: 0.254153\n",
      "[300]\tval's multi_logloss: 0.252878\n",
      "[350]\tval's multi_logloss: 0.252223\n",
      "[400]\tval's multi_logloss: 0.252018\n",
      "[450]\tval's multi_logloss: 0.252688\n",
      "[500]\tval's multi_logloss: 0.253508\n",
      "Early stopping, best iteration is:\n",
      "[403]\tval's multi_logloss: 0.252008\n",
      "(13053, 3) (13053,)\n",
      "train log loss 0.129400008867 valid log loss 0.251934575469\n",
      "rev 3.96928447848\n",
      "BETTER\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tval's multi_logloss: 0.32181\n",
      "[100]\tval's multi_logloss: 0.269544\n",
      "[150]\tval's multi_logloss: 0.258195\n",
      "[200]\tval's multi_logloss: 0.254376\n"
     ]
    }
   ],
   "source": [
    "cv_test(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
