{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 762)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train_y = train_df['author'].map(author_mapping_dict)\n",
    "train_Y = train_y\n",
    "\n",
    "\n",
    "with open('feat.pkl','rb') as fin:\n",
    "    f_train_X,f_test_X = pickle.load(fin)\n",
    "print(f_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def cv_test(k_cnt=3, s_flag = False):\n",
    "    rnd = 42\n",
    "    if s_flag:\n",
    "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    else:\n",
    "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    test_pred = None\n",
    "    weighted_test_pred = None\n",
    "    org_train_pred = None\n",
    "    avg_k_score = 0\n",
    "    reverse_score = 0\n",
    "    best_loss = 100\n",
    "    best_single_pred = None\n",
    "    for train_index, test_index in kf.split(f_train_X,train_Y):\n",
    "        X_train, X_test = f_train_X[train_index], f_train_X[test_index]\n",
    "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "\n",
    "        m = LogisticRegression(solver='newton-cg',multi_class='multinomial')\n",
    "        #m = SGDClassifier()\n",
    "        m.fit(X_train,y_train)\n",
    "        \n",
    "        # get res\n",
    "        train_pred = m.predict_proba(X_train)\n",
    "        print(train_pred.shape,y_train.shape)\n",
    "        valid_pred = m.predict_proba(X_test)\n",
    "        tmp_train_pred = m.predict_proba(f_train_X)\n",
    "        \n",
    "        # cal score\n",
    "        train_score = log_loss(y_train,train_pred)\n",
    "        valid_score = log_loss(y_test,valid_pred)\n",
    "        print('train log loss',train_score,'valid log loss',valid_score)\n",
    "        avg_k_score += valid_score\n",
    "        rev_valid_score = 1.0/valid_score # use for weighted\n",
    "        reverse_score += rev_valid_score # sum\n",
    "        print('rev',rev_valid_score)\n",
    "        \n",
    "        if test_pred is None:\n",
    "            test_pred = m.predict_proba(f_test_X)\n",
    "            weighted_test_pred = test_pred*rev_valid_score\n",
    "            org_train_pred = tmp_train_pred\n",
    "            best_loss = valid_score\n",
    "            best_single_pred = test_pred\n",
    "        else:\n",
    "            curr_pred = m.predict_proba(f_test_X)\n",
    "            test_pred += curr_pred\n",
    "            weighted_test_pred += curr_pred*rev_valid_score # fix bug here\n",
    "            org_train_pred += tmp_train_pred\n",
    "            # find better single model\n",
    "            if valid_score < best_loss:\n",
    "                print('BETTER')\n",
    "                best_loss = valid_score\n",
    "                best_single_pred = curr_pred\n",
    "\n",
    "    # avg\n",
    "    test_pred = test_pred / k_cnt\n",
    "    test_pred = np.round(test_pred,4)\n",
    "    print(test_pred.shape)\n",
    "    print(test_pred[:5])\n",
    "    org_train_pred = org_train_pred / k_cnt\n",
    "    avg_k_score = avg_k_score/k_cnt\n",
    "\n",
    "\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    submiss['EAP']=test_pred[:,0]\n",
    "    submiss['HPL']=test_pred[:,1]\n",
    "    submiss['MWS']=test_pred[:,2]\n",
    "    submiss.to_csv(\"results/lr_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('--------------')\n",
    "    print(reverse_score)\n",
    "    # weigthed\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = weighted_test_pred / reverse_score\n",
    "    weighted_test_pred = np.round(weighted_test_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/weighted_lr_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    # best single\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = np.round(best_single_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/single_lr_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    \n",
    "    # train log loss\n",
    "    print('local average valid loss',avg_k_score)\n",
    "    print('train log loss', log_loss(train_Y,org_train_pred))\n",
    "    \n",
    "print('def done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15663, 3) (15663,)\n",
      "train log loss 0.232129534135 valid log loss 0.299637033651\n",
      "rev 3.33737117811\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.234716557182 valid log loss 0.289458984507\n",
      "rev 3.45472088801\n",
      "BETTER\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.241864875343 valid log loss 0.255324307212\n",
      "rev 3.91658753888\n",
      "BETTER\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.235326548594 valid log loss 0.284167317336\n",
      "rev 3.51905352584\n",
      "(15664, 3) (15664,)\n",
      "train log loss 0.233745003524 valid log loss 0.292577190391\n",
      "rev 3.41790143881\n",
      "(8392, 3)\n",
      "[[ 0.0573  0.0247  0.918 ]\n",
      " [ 0.9754  0.0084  0.0162]\n",
      " [ 0.0045  0.9931  0.0023]\n",
      " [ 0.8792  0.1065  0.0143]\n",
      " [ 0.8476  0.101   0.0514]]\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0573  0.0247  0.9180\n",
      "1  id24541  0.9754  0.0084  0.0162\n",
      "2  id00134  0.0045  0.9931  0.0023\n",
      "3  id27757  0.8792  0.1065  0.0143\n",
      "4  id04081  0.8476  0.1010  0.0514\n",
      "--------------\n",
      "17.6456345697\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0577  0.0248  0.9175\n",
      "1  id24541  0.9754  0.0083  0.0163\n",
      "2  id00134  0.0045  0.9931  0.0023\n",
      "3  id27757  0.8790  0.1065  0.0145\n",
      "4  id04081  0.8476  0.1009  0.0515\n",
      "---------------\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0676  0.0233  0.9091\n",
      "1  id24541  0.9761  0.0081  0.0158\n",
      "2  id00134  0.0047  0.9931  0.0021\n",
      "3  id27757  0.8608  0.1180  0.0211\n",
      "4  id04081  0.8490  0.0945  0.0565\n",
      "---------------\n",
      "local average valid loss 0.284232966619\n",
      "train log loss 0.240297124112\n"
     ]
    }
   ],
   "source": [
    "cv_test(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13052, 3) (13052,)\n",
      "train log loss 0.224110674763 valid log loss 0.309719085478\n",
      "rev 3.22873225089\n",
      "(13053, 3) (13053,)\n",
      "train log loss 0.234339690543 valid log loss 0.285335997581\n",
      "rev 3.50464017326\n",
      "BETTER\n",
      "(13053, 3) (13053,)\n",
      "train log loss 0.234209614404 valid log loss 0.282613701358\n",
      "rev 3.53839886457\n",
      "BETTER\n",
      "(8392, 3)\n",
      "[[ 0.0561  0.0215  0.9223]\n",
      " [ 0.9726  0.0086  0.0189]\n",
      " [ 0.0039  0.9935  0.0026]\n",
      " [ 0.8756  0.1083  0.0161]\n",
      " [ 0.8316  0.1102  0.0581]]\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0561  0.0215  0.9223\n",
      "1  id24541  0.9726  0.0086  0.0189\n",
      "2  id00134  0.0039  0.9935  0.0026\n",
      "3  id27757  0.8756  0.1083  0.0161\n",
      "4  id04081  0.8316  0.1102  0.0581\n",
      "--------------\n",
      "10.2717712887\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0557  0.0215  0.9228\n",
      "1  id24541  0.9725  0.0085  0.0191\n",
      "2  id00134  0.0039  0.9935  0.0026\n",
      "3  id27757  0.8750  0.1095  0.0156\n",
      "4  id04081  0.8302  0.1114  0.0583\n",
      "---------------\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0421  0.0127  0.9452\n",
      "1  id24541  0.9826  0.0051  0.0123\n",
      "2  id00134  0.0050  0.9896  0.0055\n",
      "3  id27757  0.9148  0.0791  0.0060\n",
      "4  id04081  0.7843  0.1419  0.0738\n",
      "---------------\n",
      "local average valid loss 0.292556261473\n",
      "train log loss 0.24091710147\n"
     ]
    }
   ],
   "source": [
    "cv_test(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
